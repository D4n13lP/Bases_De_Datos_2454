{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             fecha_hora estacion   RH   TMP  WDR  WSP  PBa\n",
      "0      2023-01-01 01:00      ACO   81   9.3  319  1.3  NaN\n",
      "1      2023-01-01 01:00      AJU  100   2.5   36  2.4  NaN\n",
      "2      2023-01-01 01:00      MON   56  13.9  177  1.8  NaN\n",
      "3      2023-01-01 01:00      CHO                       NaN\n",
      "4      2023-01-01 01:00      CUA   61  10.9  258  1.7  NaN\n",
      "...                 ...      ...  ...   ...  ...  ...  ...\n",
      "80635  2023-04-30 24:00      INN   44   6.8  153  1.3  NaN\n",
      "80636  2023-04-30 24:00      GAM   37    20  273  1.6  NaN\n",
      "80637  2023-04-30 24:00      LAA   22  20.4  282  1.1  NaN\n",
      "80638  2023-04-30 24:00      FAR  NaN   NaN  249  2.2  NaN\n",
      "80639  2023-04-30 24:00      SAC  NaN   NaN  272  1.4  NaN\n",
      "\n",
      "[80640 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo JSON\n",
    "with open('meteorología_2023.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Inicializar una lista para almacenar las filas de la tabla\n",
    "rows = []\n",
    "\n",
    "# Unidades para las medidas (opcional para clarificar)\n",
    "units = data['pollutionMeasurements']['unit']\n",
    "\n",
    "# Iterar sobre las fechas y horas en el JSON\n",
    "for datetime, measurements in data['pollutionMeasurements']['date'].items():\n",
    "    # Para cada tipo de medición (RH, TMP, WDR, WSP, etc.)\n",
    "    for measure_type, stations in measurements.items():\n",
    "        # Para cada estación dentro de cada tipo de medición\n",
    "        for station, value in stations.items():\n",
    "            # Buscar si ya hay una fila para esta combinación de datetime y estación\n",
    "            row = next((r for r in rows if r['fecha_hora'] == datetime and r['estacion'] == station), None)\n",
    "            if row is None:\n",
    "                row = {'fecha_hora': datetime, 'estacion': station}\n",
    "                rows.append(row)\n",
    "            # Añadir la medición al diccionario\n",
    "            row[measure_type] = value\n",
    "\n",
    "# Convertir a DataFrame\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# Guardar en un archivo CSV\n",
    "df.to_csv('mediciones.csv', index=False)\n",
    "\n",
    "# Mostrar el DataFrame resultante\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Fecha y Hora Estación   RH   TMP  WDR  WSP  PBa\n",
      "0      2023-01-01 01:00      ACO   81   9.3  319  1.3  NaN\n",
      "1      2023-01-01 01:00      AJU  100   2.5   36  2.4  NaN\n",
      "2      2023-01-01 01:00      MON   56  13.9  177  1.8  NaN\n",
      "3      2023-01-01 01:00      CHO                       NaN\n",
      "4      2023-01-01 01:00      CUA   61  10.9  258  1.7  NaN\n",
      "...                 ...      ...  ...   ...  ...  ...  ...\n",
      "80635  2023-04-30 24:00      INN   44   6.8  153  1.3  NaN\n",
      "80636  2023-04-30 24:00      GAM   37    20  273  1.6  NaN\n",
      "80637  2023-04-30 24:00      LAA   22  20.4  282  1.1  NaN\n",
      "80638  2023-04-30 24:00      FAR  NaN   NaN  249  2.2  NaN\n",
      "80639  2023-04-30 24:00      SAC  NaN   NaN  272  1.4  NaN\n",
      "\n",
      "[80640 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo JSON\n",
    "with open('meteorología_2023.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Inicializar una lista para almacenar las filas de la tabla\n",
    "rows = []\n",
    "\n",
    "# Unidades para las medidas (opcional para clarificar)\n",
    "units = data['pollutionMeasurements']['unit']\n",
    "\n",
    "# Iterar sobre las fechas y horas en el JSON\n",
    "for datetime, measurements in data['pollutionMeasurements']['date'].items():\n",
    "    # Para cada tipo de medición (RH, TMP, WDR, WSP, etc.)\n",
    "    for measure_type, stations in measurements.items():\n",
    "        # Para cada estación dentro de cada tipo de medición\n",
    "        for station, value in stations.items():\n",
    "            # Buscar si ya hay una fila para esta combinación de datetime y estación\n",
    "            row = next((r for r in rows if r['fecha_hora'] == datetime and r['estacion'] == station), None)\n",
    "            if row is None:\n",
    "                row = {'fecha_hora': datetime, 'estacion': station}\n",
    "                rows.append(row)\n",
    "            # Añadir la medición al diccionario\n",
    "            row[measure_type] = value\n",
    "\n",
    "# Convertir a DataFrame\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# Guardar en un archivo CSV\n",
    "df.to_csv('mediciones.csv', index=False)\n",
    "\n",
    "# Mostrar el DataFrame resultante\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\danws\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.2)\n",
      "Collecting pymysql\n",
      "  Downloading PyMySQL-1.1.1-py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\danws\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\danws\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\danws\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\danws\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\danws\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading PyMySQL-1.1.1-py3-none-any.whl (44 kB)\n",
      "   ---------------------------------------- 0.0/45.0 kB ? eta -:--:--\n",
      "   ------------------ --------------------- 20.5/45.0 kB 320.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 45.0/45.0 kB 551.3 kB/s eta 0:00:00\n",
      "Installing collected packages: pymysql\n",
      "Successfully installed pymysql-1.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas pymysql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danws\\AppData\\Local\\Temp\\ipykernel_20676\\2952902499.py:30: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: None if pd.isna(x) else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data tuples:          fecha_hora estacion   RH   TMP  WDR  WSP   PBa\n",
      "0  2023-01-01 01:00      ACO   81   9.3  319  1.3  None\n",
      "1  2023-01-01 01:00      AJU  100   2.5   36  2.4  None\n",
      "2  2023-01-01 01:00      MON   56  13.9  177  1.8  None\n",
      "3  2023-01-01 01:00      CHO                       None\n",
      "4  2023-01-01 01:00      CUA   61  10.9  258  1.7  None\n",
      "Columns in the mediciones table: ['fecha_hora', 'estacion', 'RH', 'TMP', 'WDR', 'WSP']\n",
      "Error: Las columnas especificadas no coinciden con la estructura de la tabla 'mediciones'.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import pymysql\n",
    "\n",
    "# Cargar el archivo JSON\n",
    "with open('meteorología_2023.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Inicializar una lista para almacenar las filas de la tabla\n",
    "rows = []\n",
    "\n",
    "# Iterar sobre las fechas y horas en el JSON\n",
    "for datetime, measurements in data['pollutionMeasurements']['date'].items():\n",
    "    # Para cada tipo de medición (RH, TMP, WDR, WSP, etc.)\n",
    "    for measure_type, stations in measurements.items():\n",
    "        # Para cada estación dentro de cada tipo de medición\n",
    "        for station, value in stations.items():\n",
    "            # Buscar si ya hay una fila para esta combinación de datetime y estación\n",
    "            row = next((r for r in rows if r['fecha_hora'] == datetime and r['estacion'] == station), None)\n",
    "            if row is None:\n",
    "                row = {'fecha_hora': datetime, 'estacion': station}\n",
    "                rows.append(row)\n",
    "            # Añadir la medición al diccionario\n",
    "            row[measure_type] = value\n",
    "\n",
    "# Convertir a DataFrame\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# Reemplazar NaN por None\n",
    "df = df.applymap(lambda x: None if pd.isna(x) else x)\n",
    "\n",
    "# Comprobación adicional de los datos convertidos\n",
    "print(\"Data tuples:\", df.head())\n",
    "\n",
    "# Conectar a MySQL\n",
    "try:\n",
    "    connection = pymysql.connect(\n",
    "        host='34.72.69.10',\n",
    "        user='bd_conagua',\n",
    "        password='HkW0eiFxfT5iUv31',\n",
    "        database='conagua'\n",
    "    )\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    # Verificar la estructura de la tabla\n",
    "    cursor.execute(\"DESCRIBE mediciones\")\n",
    "    columns = [column[0] for column in cursor.fetchall()]\n",
    "    print(\"Columns in the mediciones table:\", columns)\n",
    "\n",
    "    # Asegurarse de que las columnas coinciden\n",
    "    if not all(col in columns for col in df.columns):\n",
    "        raise ValueError(\"Las columnas especificadas no coinciden con la estructura de la tabla 'mediciones'.\")\n",
    "\n",
    "    # Preparar los datos para la inserción\n",
    "    data_tuples = [tuple(x) for x in df.to_numpy()]\n",
    "    cols = \",\".join([str(i) for i in df.columns.tolist()])\n",
    "\n",
    "    # Insertar los datos\n",
    "    insert_query = f\"INSERT INTO mediciones ({cols}) VALUES ({', '.join(['%s'] * len(df.columns))})\"\n",
    "    cursor.executemany(insert_query, data_tuples)\n",
    "    connection.commit()\n",
    "\n",
    "except pymysql.MySQLError as e:\n",
    "    print(f\"Error al conectar a la base de datos: {e}\")\n",
    "except ValueError as ve:\n",
    "    print(f\"Error: {ve}\")\n",
    "finally:\n",
    "    if connection:\n",
    "        cursor.close()\n",
    "        connection.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "# Conectar a MySQL\n",
    "connection = pymysql.connect(\n",
    "    host='34.72.69.10',\n",
    "    user='bd_conagua',\n",
    "    password='HkW0eiFxfT5iUv31',\n",
    "    database='conagua'\n",
    ")\n",
    "\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Crear la tabla si no existe\n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS mediciones (\n",
    "    fecha_hora DATETIME,\n",
    "    estacion VARCHAR(50),\n",
    "    RH FLOAT,\n",
    "    TMP FLOAT,\n",
    "    WDR FLOAT,\n",
    "    WSP FLOAT,\n",
    "    PRIMARY KEY (fecha_hora, estacion)\n",
    ")\n",
    "\"\"\"\n",
    "cursor.execute(create_table_query)\n",
    "connection.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "not all arguments converted during string formatting",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Insertar los datos\u001b[39;00m\n\u001b[0;32m      6\u001b[0m insert_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mINSERT INTO mediciones (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcols\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) VALUES (%s, %s, %s, %s, %s, %s)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 7\u001b[0m \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecutemany\u001b[49m\u001b[43m(\u001b[49m\u001b[43minsert_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_tuples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m connection\u001b[38;5;241m.\u001b[39mcommit()\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Cerrar la conexión\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\danws\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pymysql\\cursors.py:182\u001b[0m, in \u001b[0;36mCursor.executemany\u001b[1;34m(self, query, args)\u001b[0m\n\u001b[0;32m    180\u001b[0m     q_postfix \u001b[38;5;241m=\u001b[39m m\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m3\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m q_values[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m q_values[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_execute_many\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mq_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mq_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mq_postfix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_stmt_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_db\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrowcount \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(query, arg) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args)\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrowcount\n",
      "File \u001b[1;32mc:\\Users\\danws\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pymysql\\cursors.py:205\u001b[0m, in \u001b[0;36mCursor._do_execute_many\u001b[1;34m(self, prefix, values, postfix, args, max_stmt_length, encoding)\u001b[0m\n\u001b[0;32m    203\u001b[0m sql \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytearray\u001b[39m(prefix)\n\u001b[0;32m    204\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(args)\n\u001b[1;32m--> 205\u001b[0m v \u001b[38;5;241m=\u001b[39m \u001b[43mvalues\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mescape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    207\u001b[0m     v \u001b[38;5;241m=\u001b[39m v\u001b[38;5;241m.\u001b[39mencode(encoding, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msurrogateescape\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: not all arguments converted during string formatting"
     ]
    }
   ],
   "source": [
    "# Preparar los datos para la inserción\n",
    "data_tuples = [tuple(x) for x in df.to_numpy()]\n",
    "cols = \",\".join([str(i) for i in df.columns.tolist()])\n",
    "\n",
    "# Insertar los datos\n",
    "insert_query = f\"INSERT INTO mediciones ({cols}) VALUES (%s, %s, %s, %s, %s, %s)\"\n",
    "cursor.executemany(insert_query, data_tuples)\n",
    "connection.commit()\n",
    "\n",
    "# Cerrar la conexión\n",
    "cursor.close()\n",
    "connection.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data tuples: [(1.0, 'A', 10.5), (2.0, 'B', None), (None, 'C', 12.3)]\n",
      "Columns in the mediciones table: ['fecha_hora', 'estacion', 'RH', 'TMP', 'WDR', 'WSP']\n",
      "Error: Las columnas especificadas no coinciden con la estructura de la tabla 'mediciones'.\n"
     ]
    }
   ],
   "source": [
    "import pymysql\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Supongamos que 'data' es tu DataFrame de Pandas\n",
    "data = pd.DataFrame({\n",
    "    'col1': [1, 2, np.nan],\n",
    "    'col2': ['A', 'B', 'C'],\n",
    "    'col3': [10.5, np.nan, 12.3]\n",
    "})\n",
    "\n",
    "# Reemplazar NaN por None\n",
    "data = data.map(lambda x: None if pd.isna(x) else x)\n",
    "\n",
    "# Convertir los datos a una lista de tuplas\n",
    "data_tuples = [tuple(None if pd.isna(x) else x for x in row) for row in data.itertuples(index=False, name=None)]\n",
    "\n",
    "# Comprobación adicional de los datos convertidos\n",
    "print(\"Data tuples:\", data_tuples)\n",
    "\n",
    "# Conectar a MySQL\n",
    "try:\n",
    "    connection = pymysql.connect(\n",
    "        host='34.72.69.10',\n",
    "        user='bd_conagua',\n",
    "        password='HkW0eiFxfT5iUv31',\n",
    "        database='conagua'\n",
    "    )\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    # Verificar la estructura de la tabla\n",
    "    cursor.execute(\"DESCRIBE mediciones\")\n",
    "    columns = [column[0] for column in cursor.fetchall()]\n",
    "    print(\"Columns in the mediciones table:\", columns)\n",
    "\n",
    "    # Asumiendo que tu tabla tiene columnas correspondientes\n",
    "    cols = 'col1, col2, col3'\n",
    "    if not all(col in columns for col in cols.split(', ')):\n",
    "        raise ValueError(\"Las columnas especificadas no coinciden con la estructura de la tabla 'mediciones'.\")\n",
    "\n",
    "    insert_query = f\"INSERT INTO mediciones ({cols}) VALUES (%s, %s, %s)\"\n",
    "\n",
    "    # Insertar los datos\n",
    "    cursor.executemany(insert_query, data_tuples)\n",
    "    connection.commit()\n",
    "\n",
    "except pymysql.MySQLError as e:\n",
    "    print(f\"Error al conectar a la base de datos: {e}\")\n",
    "except ValueError as ve:\n",
    "    print(f\"Error: {ve}\")\n",
    "finally:\n",
    "    if connection:\n",
    "        connection.close()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
